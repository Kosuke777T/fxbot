T-42 最終まとめ

（予測AI検証フェーズの完了報告と設計上の確定事項）

1. T-42の目的と結論
目的

価格系列（OHLCV + テクニカル指標）を用いて
短期のBUY/SELL（二値）を予測できるかを検証する。

モデル性能だけでなく、
**実運用に耐えるか（再現性・自動化・安全性）**まで含めて評価する。

結論（最重要）

短期二値予測は成立しない
（AUC ≒ 0.5、ROCがほぼ対角線、Calibrationも意味を持たない）

これはモデルや実装の失敗ではなく、
問題設定（問い）が市場構造に合っていないことが原因。

よって 「予測AIとしてのT-42」は科学的に否定され、完了した。

2. 技術的に達成したこと（事実）
2.1 推論パイプラインの完全確立

以下が 1コマンドで再現可能な状態になった：

特徴量生成

モデルロード（active_model.json 経由）

推論（predict_proba）

評価データ出力（npy）

指標算出（AUC / LogLoss / Brier）

可視化（ROC / Calibration）

成果物存在チェック

→ scripts/val_smoke.py により 自動検証可能。

2.2 active_model.json を唯一の真実に固定

ここは今後の事故防止で極めて重要。

推論・評価・運用で使うモデルは
必ず models/active_model.json を経由して決定する

直ロード・直指定は禁止

3. 重要な「決め事」（今後絶対に忘れてはいけない）
3.1 特徴量は「20個」で固定する

これを破ると再び事故る。

採用した特徴量（20）
open, high, low, close,
tick_volume, spread, real_volume,
ret1, ret5, ret20,
sma_10, sma_50,
ema_20,
rsi_14,
bb_high_20_2, bb_low_20_2,
stoch_k_14_3, stoch_d_14_3,
atr_14,
vol_pct_20


この順序を含めてモデルの一部

feature_order は必ず model.feature_name_ に従う

推論側で勝手に並び替えない

3.2 active として採用したモデル

ファイル：models/LightGBM_clf.pkl

型：lightgbm.sklearn.LGBMClassifier

n_features_in_：20

9特徴Boosterモデルは 退役（参考用）

3.3 「Warningを消すために形状チェックを無効化しない」

以下は 絶対禁止：

predict_disable_shape_check=true


理由：

バグを隠すだけ

モデルとデータの不整合を見逃す

将来の損失に直結する

4. 評価結果から得られた知見（設計判断）
4.1 ROC / Calibration の意味

ROCが対角線 → 順位付け能力ゼロ

Calibrationが崩壊 → 確率に意味がない

しきい値をどう変えても precision ≒ 0.5

→ 市場は短期二値予測に必要な情報を含んでいない

4.2 「モデルが弱い」のではない

LightGBMは正常

特徴量も一般的で妥当

実装・評価も正しい

問題は「次が上か下か」を直接聞いたこと。

5. T-42で“やらない”と決めたこと

❌ 予測精度を無理に上げようとする

❌ 特徴量をさらに増やすだけの改良

❌ キャリブレーションで誤魔化す

❌ AUC 0.5 を「失敗」と扱う

これらは 方向を誤らせるため、意図的に採用しない。

6. T-42からT-43へ引き継ぐ思想
T-42の到達点

「当てるAI」は市場構造に合わない

次フェーズ（T-43）の前提

未来を当てない

過去の条件×結果を根拠として提示する

Ops（人 or ルール）が意思決定する

AIは「判断材料の供給役」

7. 今後のミスを減らすためのチェックリスト

 特徴量数は 20 か？

 feature_order は model.feature_name_ と一致しているか？

 active_model.json を経由しているか？

 予測を“意思決定そのもの”に使っていないか？

 val_smoke.py が通るか？

8. 総括

T-42は「当たらなかった実験」ではない。
「当てに行くべきではない」ことを、再現可能な形で証明した実験である。

これは戦略設計において
**最も価値の高い失敗（＝成功）**の一種。