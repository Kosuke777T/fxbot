MT5 時刻ズレ修正 → CSVが最新足まで追記）
0) 症状（最初に起きていたこと）

MT5の最新M5は進んでいるのに、USDJPY_M5.csv の time.max が 2026-01-19 15:00:00 で止まり続ける

ensure_ohlcv_uptodate() は mt5_last が進んでいるのに append_rows=0 のまま

copy_rates_range() が返す max が変、copy_rates_from() フォールバックも collected 0 rows になっていた

1) 原因（確定）

MT5が返す tick.time(epoch) がローカルの now_epoch より約 +2時間未来になっていた

観測ログ：delta_sec=7198 → delta_hours_round=2

その結果、epoch→JST 変換を “UTC基準” として扱うロジックがズレて、

range取得の時刻が不正

fallback paging の “終端 dt_to” も不正

→ 必要区間に入らず 0行になる

2) 対応方針（最小差分）

“ミチビキ内部の naive datetime は JST” を前提に維持したまま、

MT5のepochがUTCからズレている分だけ補正する（+2h 等）

さらに、MT5 APIが naive datetime を「サーバ時刻」として解釈している可能性に備えて、

fallback（copy_rates_from）に渡す dt_to を server-naive に寄せる

3) 実装した修正（要点）
A. SERVER_OFFSET_SEC を導入（グローバル）

SERVER_OFFSET_SEC: int = 0 を追加

main() の [time_audit] で now_epoch と tick_epoch の差分から 1時間丸めで確定

例：SERVER_OFFSET_SEC = 7200

B. epoch→JST変換 jst_from_mt5_epoch() に補正を追加

pd.to_datetime(..., utc=True) で作った時刻から
SERVER_OFFSET_SEC を引いて補正してから JST化する

C. copy_rates_from() 用に _to_server_naive() を追加

JST naive → server naive（= “壁時計”）に寄せる

fallback では dt_to = _to_server_naive(end_ts) を使うよう変更

D. 観測ログを強化してチョークポイントを可視化

[time_audit]（ローカルとMT5のズレ）

rangeの range_insufficient ログ

fallbackの df_raw.time.max epoch / utc / jst ログ

df_new.time dtype と merged.max ログ

4) 結果（観測で確定：復旧）

SERVER_OFFSET_SEC=7200 を観測で確定

fallbackが collected 0 → fetched rows=57 に改善

USDJPY_M5.csv の末尾が更新：

csv_tail_before: 2026-01-19 15:00:00

csv_tail_after : 2026-01-19 19:45:00

append_rows=57

CSV実体でも確認：

time.max: 2026-01-19 19:45:00

rows: 112816

5) 2026-01-19 15:00:00 は何の時間だった？

これは “CSV（JST naive運用）の最終ローソク足の時刻”

当初は時刻ズレのせいで、その先（15:05〜）が取得・マージされず、CSVの最終時刻が15:00で固定されていた

今回の補正で 15:05以降が入って更新された

6) いまの状態（完了判定）

✅ UnicodeDecodeError も解消済み（subprocess出力デコード耐性）

✅ symbol正規化（CSVパス用）と MT5 symbol（実取得用）の分離も完了

✅ 時刻ズレ（server_offset +2h）を吸収して、M5自動更新が最新足まで追記できる状態に復旧

✅ ensure_ohlcv_uptodate() が append_rows > 0 を出し、推論も動く（infer_rowsが出る）

1. 問題の正体（根本原因）

MT5 が返す epoch（tick / bar）が「UTCではなくサーバ時刻基準」だった

その結果、

PC時刻（JST/UTC）

MT5 tick.time

MT5 bar.time
が 常に約 +2時間ズレる 状態になっていた

過去に入れた「時間軸統一（JST naive）」処理が
“UTCとして解釈してはいけない epoch” を UTC として扱ってしまったのが決定打

2. 正しく観測できるようにしたこと

以下を 同時にログで比較できる状態を構築：

PC now_epoch

tick_epoch

latest_bar_epoch

UTC / JST 変換後の値

これにより
👉 tick / bar が常に PC より約2時間先
👉 サーバオフセットが安定して存在
という事実を確定できた

3. 解決方針（設計として正しい形）
原則

内部表現は JST naive で統一

MT5との境界だけで補正する

epoch を「UTCと信じない」

4. 実装したコア修正
① SERVER_OFFSET_SEC を導入

MT5サーバ時刻 − PC時刻 を 秒で保持

以降の変換はすべてこれを基準に補正

② update_server_offset() を追加・安全化

tick_epoch - time.time() から 毎回再推定

ただし安全装置付き：

安全ガード

15分未満 → ノイズとして無視

1時間以上のジャンプ → 無視（ログのみ）

時間単位に丸めて安定化

👉 ブローカー変更・DST・再起動でも壊れない

③ jst_from_mt5_epoch() を修正

変更前：
epoch → UTC → JST（❌ズレる）

変更後：
epoch → UTC → SERVER_OFFSET補正 → JST（✅正しい）

④ _to_server_naive() を新設

JST naive → MT5が期待する「サーバ時刻 naive」 に変換

copy_rates_from() のフォールバックで使用

5. 結果（確認済み）

✅ copy_rates_from() が 0行問題を解消

✅ CSV の time.max が 15:00 → 19:45 → 最新まで進行

✅ append_rows > 0 を安定して観測

✅ 推論（infer）も最新足を正しく使用

✅ latest_bar_jst が論理的に一貫

6. GUIが更新されなかった件の修正
問題

GUI起動時、JobScheduler が回っていなかった

デーモン前提の設計だった

対応

GUI起動時に：

SchedulerTickRunner を追加

run_pending() を QTimer + サブスレッドで10秒ごとに実行

結果

GUI起動中でも：

ohlcv_m5_auto_update

run_always: true
が確実に回る

7. 今の状態の評価（重要）

結論：今の実装は「実運用に耐える状態」

時刻ズレは 構造的に解消

MT5依存の癖（サーバ時刻）を 境界で吸収

将来の変更にも強い（自動再推定）

🧠 このスレッドで確立した設計原則（今後の指針）

epochは信じるな

MT5との境界でのみ時刻補正

内部はJST naiveで統一

観測ログが先、推測は後

これはかなり“強い基盤”です。

JobScheduler の二重実行対策（生成／ロード／再読込の完全安全化）

1. 問題の正体（観測で確定）

GUI 起動時に JobScheduler が複数生成・複数ロードされる可能性があった

ただし推測では直さず、
pid / scheduler_id / thread_id をログに出して観測した結果：

同一プロセス内の二重生成は GUI 側の直 new が原因

ログ多重や別プロセス（daemon）も 区別可能な状態に確定

2. 実施した対策（最小差分・責務厳守）
(1) 二重生成対策

GUI 側の JobScheduler() 直生成を廃止

scheduler_facade.get_scheduler() に統一（シングルトン）

観測ログで scheduler_id 一致を確認

(2) 観測パッチ追加

_load_jobs() に以下を付与

pid / scheduler_id / thread_id

get_scheduler() 初回返却時に scheduler_id をログ出力

二重生成／ログ多重／別プロセスをログだけで切り分け可能に

(3) _load_jobs() 冪等化（最終防衛線）

self._jobs_loaded: bool を追加

同一インスタンスで複数回呼ばれても
→ 2回目以降は early return + ignored ログ

エラー時はフラグを立てず、再試行可能

(4) reload() の再読込保証

reload() 冒頭で self._jobs_loaded = False

冪等化と再読込を両立

ログが嘘をつかない状態を保証

3. 最終観測結果（決定的証拠）

GUI起動ごとに

[JobScheduler] loaded ... は 1回のみ

scheduler_id は get_scheduler() と一致

reload() 呼び出し時

loaded ... が再度出力され、確実に再読込

_load_jobs() 連続呼び出し

ignored already_loaded=True が正しく出力

👉 二重生成・二重ロード・二重実行は完全に封殺

4. 現在の状態（完成形）

JobScheduler は シングルトン保証

初期ロードは 1回だけ

再読込は 明示的に reload() のみ

将来どこかで誤って多重呼び出しされても 壊れない

問題が再発しても ログだけで即原因特定可能


MT5→CSV 生成処理の“静かに壊れる”事故を防ぐ最低限ガードの実装

1. 背景（何が危険だったか）

サーバ時刻オフセット（+2h 前提）が将来変動すると
→ CSV時刻の逆行・欠損・重複が起きても 気づかず進行する危険

CSV追記ロジックが tail基準のため、時刻が戻ると
→ append_rows=0 のまま「止まったように見える」事故

単調増加チェックが sort_values() を使っており、
→ 常にTrueになりやすい＝ガードが空振りする状態だった

2. 実施した対策（すべて最小差分）
① サーバ時刻オフセットの監視強化

対象: scripts/make_csv_from_mt5.py

update_server_offset() に以下を追加

毎回 effective_offset_sec / prev_offset_sec / delta_sec を INFOログ

abs(delta_sec) >= 3600 の場合は WARNING

ジャンプ抑制が働いた場合も WARNING を明示

結果
→ オフセットが変動した瞬間にログで検知可能

② CSV保存直前の“時刻逆行ガード”追加

対象: scripts/make_csv_from_mt5.py

CSV保存直前で以下をチェック

merged["time"].is_monotonic_increasing

崩れていた場合

[time_audit][WARNING] を出力

tail_time より古い行数をログ出力

その回のCSV保存をスキップ

結果
→ 壊れたデータがCSVに混入しない

③ 単調増加チェックの致命バグ修正（重要）

修正内容

❌ merged["time"].sort_values().is_monotonic_increasing を削除

✅ merged["time"].is_monotonic_increasing を直接チェック

追加観測

WARNING時のみ

merged["time"].head(3)

merged["time"].tail(3)
をログ出力（事故解析用）

結果

ガードが 本当に機能する状態 に修正された

“エアバッグが開かない”状態を解消

3. 動作確認

python -X utf8 -m py_compile scripts/make_csv_from_mt5.py
→ 成功

正常ケース
→ CSV保存・ログは従来通り

異常ケース（時刻逆行・offset異常）
→ WARNINGが出て 保存されない

4. 現在の状態（何が保証されたか）

サーバ時刻オフセットの揺れを 即検知

時刻逆行・混入データを CSVに保存しない

壊れた瞬間に止まり、
「静かに壊れて後で地獄」になる経路を遮断

大改修（UTC化・取得戦略変更）なしで安全度を大幅向上

5. まだ残っているが、今は致命でない課題

WARNINGが連続した場合の 自動停止／UI通知

copy_rates_range 依存の揺れ（設計課題）

JST naive 前提の長期的な時刻契約（将来対応）

※ いずれも 「検知できず壊れる」状態ではなくなったため、優先度は下げられた。

結論

今回の作業で
「時刻がズレた瞬間に分かって止まる」最低限の安全ライン は完成。
この状態なら、開発を続けても事故は“早期に見える形”で表面化します。

#今後起こりうる問題
今の状態でも「動く」けど、このまま開発を続けると起きやすい問題はわりとハッキリしてる。ざっくり言うと “+2時間補正が正しい前提” をコードが抱え込んでしまったのが最大の地雷。

1) サーバ時刻オフセットが変動すると壊れる（最重要）

今回 SERVER_OFFSET_SEC=7200（+2h）を、tick.time と now_epoch の差から丸めて決めてるよね。
これ、以下で変わり得る：

ブローカー/サーバの運用（DST/サマータイム、サーバ移行、メンテ）

端末PCの時計ズレやNTP不調

MT5が返す tick.time の意味（サーバ時刻扱い）の揺れ

変動した瞬間に

CSVの時間が飛ぶ/戻る

取得がまた0行になったり、重複・欠損が出たり
が起きる。

対策の方向性：
SERVER_OFFSET_SEC は「観測して自動推定」でもいいけど、(a) ログに毎回出して監視、(b) しきい値超えで警告/停止、(c) できれば設定で固定 or MT5側の公式情報で確定、が安全。

2) JST naive の“内部標準”が増殖して、別系統の時刻と混ざる

今の実装は「ミチビキ内部の naive datetime は JST」というローカルルールで回ってる。
これ自体はアリなんだけど、

他のサービスが UTC-aware を返す

pandas が timezone を持ったSeriesを返す

JSONLに tz付きISOが混ざる

みたいな経路が増えると、同じ“19:45”でも意味が違う事故が起きる。

症状例：可視化は合ってるのに、推論の時系列がズレる／ラベルが逆転／窓関数の境界がずれる。

対策：
「保存（CSV/JSONL）」「内部計算」「MT5入出力」の3境界だけでも、必ずどの時刻表現かを固定するのが吉（例：保存はUTC ISO8601、内部はUTC-aware、表示だけJST、みたいな）。

3) copy_rates_range と copy_rates_from の“解釈差”が残る

今回 _to_server_naive() を fallback に入れたけど、range系は3方式トライで、まだ挙動がサーバやビルドで揺れやすい。

症状例：
ある日は range がまともに埋まるが、別の日は range_insufficient→fallback の頻度が増える、など。

対策：
「rangeは信用せず、常にfrom_posで最新N本＋CSV追記」みたいな 取得戦略の単純化が一番安定。

4) append_rows の計算が“CSV tail基準”なので、時間が戻ると壊れる

もし何かの拍子に変換が逆転して、CSVに 過去の時刻が混ざると

tailが更新されない

dedupで消える

append_rowsが0のまま
になって「また止まった」に見える。

対策：
CSVに書く直前に 単調増加チェック（timeが増えてない行が混ざったら警告・スキップ）を入れると強い。

じゃあ「今すぐ」やるべき最低限の安全策は？

コードを大きく変えずに、事故を早期発見できるやつ：

SERVER_OFFSET_SEC を毎回 INFO で出す（すでに出てるならOK）

前回の offset と違ったら WARNING（±3600以上変化で停止でもいい）

CSV書き込み前に merged["time"].is_monotonic_increasing をチェックして、崩れてたら WARNING + その回は保存しない

これだけで「静かに壊れて、あとで地獄」確率が激減する。

結論：
今の状態で続けると問題が出る可能性はあるけど、危険の中心は server offset の揺れと naive/JSTの混在。
先に「ズレが起きた瞬間に検知して止まる」ガードを入れておけば、開発速度を落とさずに安全に進められる。


目的

M5 OHLC CSV の自動追記に追随して、LightGBM 推論値を 未推論分のみ 計算・追記し、
GUI（Visualizeタブ）で スクロールしても消えない・時系列整合が崩れない 状態を作る。

最終到達状態（成功条件の達成）

✅ proba CSV は append-only のまま運用

✅ 読み取り時のみ 必ず time 昇順ソートを実施

✅ 「CSV最終行＝最新」依存を完全排除（max(time) を使用）

✅ 横スクロールで過去OHLCを表示しても LightGBM 出力が消えない

✅ 表示範囲に不足があれば その範囲だけ再計算

✅ 世代管理は (time, model_id) で安定

✅ GUI は services 経由のみ（責務境界厳守）

✅ compileall / py_compile 通過

実施した主要修正
1. visualization_service.py

get_recent_lgbm_series() にて

read_csv 直後に 強制ソート（time, mergesort）

iloc[-1] / tail依存 を排除し max(time) に統一

観測ログを一時 INFO → DEBUG に戻して静音化

表示用データは 常に昇順保証

2. ohlcv_update_service.py

ensure_lgbm_proba_uptodate() の model_id 取得を関数冒頭1箇所に統合

重複ブロック・インデント崩れを完全除去

range指定（start_time / end_time）と世代管理の挙動を安定化

append-only + (time, model_id) 重複禁止を維持

3. GUI（visualize_tab.py）

OHLC表示範囲を先に確定 → services に範囲を渡して proba を補完

描画は lgbm.time ベース（len一致前提を廃止）

観測で確認できた証拠

[viz] lgbm loaded ... sorted=True

head < tail の time が DEBUG ログで確認可能

[lgbm] ... range_start=... range_end=... appended=...

スクロール操作に応じて rows が段階的に増加

解消した「地雷」

CSV行順＝時系列という誤前提

model_id が途中で変わり得る重複取得ロジック

OHLC と proba の len 不一致による描画消失

将来の range × 世代管理の不定挙動リスク

現在の設計的特徴（重要）

CSVは履歴ログ（append-only）

時系列整合は常に読み取り側で保証

世代切替・過去補完・GUI表示がすべて両立